{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tweets analysis.ipynb","provenance":[],"authorship_tag":"ABX9TyMxpjir9Ao93RhrJLtYyr3O"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dp2-dbyH9ji-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1597687497065,"user_tz":-120,"elapsed":2312,"user":{"displayName":"Huimin Xu","photoUrl":"","userId":"00356707055422858355"}},"outputId":"18df40f9-86da-44eb-a90f-d33451fef7c2"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","!ls '/content/drive/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","'My Drive'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"76kajyLjgEc3","colab_type":"code","colab":{}},"source":["import os\n","# Create a new directory 'Tweets' to store the crawled tweets\n","path = '/content/drive/My Drive/AI Capstone/Tweets month data from 2015 to 2020/Tweets'\n","os.mkdir(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bJsAPxOJ1Mx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1597690497960,"user_tz":-120,"elapsed":7939,"user":{"displayName":"Huimin Xu","photoUrl":"","userId":"00356707055422858355"}},"outputId":"ae28c39e-1d85-4c79-a736-6afbc2bd979f"},"source":["# download libraries for tweets scraping\n","!pip install GetOldTweets3\n","!pip install unicodecsv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: GetOldTweets3 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n","Requirement already satisfied: pyquery>=1.2.10 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (1.4.1)\n","Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n","Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n","Requirement already satisfied: unicodecsv in /usr/local/lib/python3.6/dist-packages (0.14.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cQsZu9yz7tkP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1597690504035,"user_tz":-120,"elapsed":4624,"user":{"displayName":"Huimin Xu","photoUrl":"","userId":"00356707055422858355"}},"outputId":"78545ff7-38ed-4da8-9854-cb678f41b706"},"source":["# download libraries for tweets analysis\n","!pip install -U textblob-de"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: textblob-de in /usr/local/lib/python3.6/dist-packages (0.4.3)\n","Requirement already satisfied, skipping upgrade: textblob>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from textblob-de) (0.15.3)\n","Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob>=0.9.0->textblob-de) (3.2.5)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob>=0.9.0->textblob-de) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o9lQ7X4Tj8xg","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K6szCLIxjxsT","colab_type":"text"},"source":["**Part 1: Tweets scraping**"]},{"cell_type":"code","metadata":{"id":"9RcH_eU9JNx7","colab_type":"code","colab":{}},"source":["# import libraries\n","import tweepy\n","import GetOldTweets3 as got\n","import unicodecsv as csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ihsSCm4eJN1C","colab_type":"code","colab":{}},"source":["# input the user access tokens\n","consumer_key = '4ATVIJAX4vvGK5FumwjP47puP'\n","consumer_secret = 'cfdOnzB53poxC3T6N4RUCBhiyBD3zjomAjkjJYPV7BGAKoHSE0'\n","\n","access_token = '1079131550179037186-JRa2cfOwLcl84VGTjUUi30mUtJRyHz'\n","access_token_secret = 'NcK1W6DG3emIihoYd1PZ28qIu4O06E7aTh84NdkBinzXG'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nEv9J_NkJN3r","colab_type":"code","colab":{}},"source":["auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","auth.set_access_token(access_token, access_token_secret)\n","\n","api = tweepy.API(auth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6_z96JUJN6f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"error","timestamp":1597691154795,"user_tz":-120,"elapsed":641111,"user":{"displayName":"Huimin Xu","photoUrl":"","userId":"00356707055422858355"}},"outputId":"58991ff9-ae16-49f2-9604-ac2aca6de3c7"},"source":["# For year 2015 to 2020 crawl tweets with the setted criterion and write it in csv files\n","# download it in the folder 'Tweets'\n","for Year in range(2015, 2021):\n","    i = 1\n","    while i in range(1, 13):\n","        if i in range(1, 12):\n","            tweetCriteria = got.manager.TweetCriteria().setQuerySearch('Bier' or 'Brauerei')\\\n","                                                       .setSince(\"{}-{}-01\".format(Year, i))\\\n","                                                       .setUntil(\"{}-{}-01\".format(Year, i + 1))\\\n","                                                       .setMaxTweets(0)\\\n","                                                       .setLang('de')\\\n","                                                       .setNear('Hessen, Germany')\\\n","                                                       .setWithin('400km')\n","            tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n","            # Open/create a file to append data to\n","            csvFile = open('/content/drive/My Drive/AI Capstone/Tweets month data from 2015 to 2020/Tweets/result_{}_{}.csv'.format(Year, i), 'wb+')\n","            #Use csv writer\n","            csvWriter = csv.writer(csvFile)\n","\n","            for t in tweet:\n","                # Write a row to the CSV file.\n","                csvWriter.writerow([t.formatted_date, t.text])\n","                #print(t.formatted_date, t.text)\n","            csvFile.close()\n","            \n","        else:\n","            tweetCriteria = got.manager.TweetCriteria().setQuerySearch('Bier' or 'Brauerei')\\\n","                                                       .setSince(\"{}-12-01\".format(Year))\\\n","                                                       .setUntil(\"{}-1-01\".format(Year + 1))\\\n","                                                       .setMaxTweets(0)\\\n","                                                       .setLang('de')\\\n","                                                       .setNear('Hessen, Germany')\\\n","                                                       .setWithin('400km')\n","            tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n","            # Open/create a file to append data to\n","            csvFile = open('/content/drive/My Drive/AI Capstone/Tweets month data from 2015 to 2020/Tweets/result_{}_12.csv'.format(Year), 'wb+')\n","            #Use csv writer\n","            csvWriter = csv.writer(csvFile)\n","\n","            for t in tweet:\n","                # Write a row to the CSV file.\n","                csvWriter.writerow([t.formatted_date, t.text])\n","                #print(t.formatted_date, t.text)\n","            csvFile.close()\n","            \n","        i = i + 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n","Try to open in browser: https://twitter.com/search?q=Bier%20near%3A%22Hessen%2C%20Germany%22%20within%3A400km%20since%3A2020-7-01%20until%3A2020-8-01&src=typd\n"],"name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Bvj8H4_9JOIo","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g_GFSOOajkEb","colab_type":"text"},"source":["**Part 2: Tweets sentiment analysis**"]},{"cell_type":"code","metadata":{"id":"CxP5bYJClGc-","colab_type":"code","colab":{}},"source":["# import the libraries\n","from textblob_de import TextBlobDE as TextBlob\n","import pandas as pd\n","import re\n","import csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9LPYDuu8Bf1","colab_type":"code","colab":{}},"source":["# clean tweets with regular expression\n","FLAGS = re.MULTILINE | re.DOTALL\n","def cleanTxt(text):\n","    text = re.sub(r\"@\\S+\", \"<user>\", text, flags=FLAGS) #replace @mentions with '<user>'\n","    text = re.sub(r'#', '', text, flags=FLAGS) #remove the '#' symbol \n","    text = re.sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*|~http\", \"<url>\", text, flags=FLAGS) #replace the hyperlink with '<url>'\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WiyLQRVm8GCS","colab_type":"code","colab":{}},"source":["# create a function to get the polarity\n","def getPolarity(text):\n","    return TextBlob(text).sentiment.polarity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fS5w2hxf8JBL","colab_type":"code","colab":{}},"source":["#create a function to compute the negative, neutral and postive analysis\n","def getAnalysis(score):\n","    if score < 0:\n","        return 'Negative'\n","    elif score == 0:\n","        return 'Neutral'\n","    else:\n","        return 'Positive'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOVLmUAuny8D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1597691275906,"user_tz":-120,"elapsed":2056,"user":{"displayName":"Huimin Xu","photoUrl":"","userId":"00356707055422858355"}},"outputId":"bdb76270-ea4c-4f62-bff7-b10fdca28ccb"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":129}]},{"cell_type":"code","metadata":{"id":"9eIr4Sn28Mmw","colab_type":"code","colab":{}},"source":["# Open/create a file to append data to\n","csvFile = open('/content/drive/My Drive/AI Capstone/Tweets month data from 2015 to 2020/Tweets/Hessen_2015_2020_percentages_of_pntweets.csv', 'w')\n","\n","#Use csv writer\n","csvWriter = csv.writer(csvFile)\n","\n","csvWriter.writerow([\"Year_Month\",\"Tweet_Counts\",\"Positive_Percentage(%)\", \"Negative_Percentage(%)\"])\n","\n","\n","# data of the year 2015 to 2019 from month 1 to 12\n","for year in range(2015, 2020):\n","    for i in range(1, 13):\n","        with open('/content/drive/My Drive/AI Capstone/Tweets month data from 2015 to 2020/Tweets/result_{}_{}.csv'.format(year, i)) as csvfile:\n","\n","            header_list = [\"Datetime\", \"Tweet\"]\n","            log = pd.read_csv(csvfile, header=None, names=header_list) \n","            #'Bier' or 'Brauerei' are in the sentence\n","            df = pd.DataFrame([tweet for tweet in log['Tweet'] if 'Bier' or 'Brauerei' in tweet], columns=['Tweets'])\n","            # clean the text\n","            df['Tweets'] = df['Tweets'].apply(cleanTxt)\n","            # create new columns\n","            df['Polarity'] = df['Tweets'].apply(getPolarity)\n","            df['Analysis'] = df['Polarity'].apply(getAnalysis)\n","\n","            # get the percentage of positive tweets\n","            ptweets = df[df.Analysis == 'Positive']\n","            ptweets = ptweets['Tweets']\n","\n","            per_ptweets = round((ptweets.shape[0]/df.shape[0])*100, 1)\n","\n","            # get the percentage of negative tweets\n","            ntweets = df[df.Analysis == 'Negative']\n","            ntweets = ntweets['Tweets']\n","\n","            per_ntweets = round((ntweets.shape[0]/df.shape[0])*100, 1)\n","\n","            # Write a row to the CSV file.\n","            csvWriter.writerow(['{}_{}'.format(year, i),df.shape[0],per_ptweets,per_ntweets])\n","\n","\n","# data of the year 2020 from month 1 to 6\n","for i in range(1, 7):\n","        with open('/content/drive/My Drive/AI Capstone/Tweets month data from 2015 to 2020/Tweets/result_2020_{}.csv'.format(i)) as csvfile:\n","\n","            header_list = [\"Datetime\", \"Tweet\"]\n","            log = pd.read_csv(csvfile, header=None, names=header_list) \n","            #'Bier' or 'Brauerei' are in the sentence\n","            df = pd.DataFrame([tweet for tweet in log['Tweet'] if 'Bier' or 'Brauerei' in tweet], columns=['Tweets'])\n","            # clean the text\n","            df['Tweets'] = df['Tweets'].apply(cleanTxt)\n","            # create new columns\n","            df['Polarity'] = df['Tweets'].apply(getPolarity)\n","            df['Analysis'] = df['Polarity'].apply(getAnalysis)\n","\n","            # get the percentage of positive tweets\n","            ptweets = df[df.Analysis == 'Positive']\n","            ptweets = ptweets['Tweets']\n","\n","            per_ptweets = round((ptweets.shape[0]/df.shape[0])*100, 1)\n","\n","            # get the percentage of negative tweets\n","            ntweets = df[df.Analysis == 'Negative']\n","            ntweets = ntweets['Tweets']\n","\n","            per_ntweets = round((ntweets.shape[0]/df.shape[0])*100, 1)\n","\n","            # Write a row to the CSV file.\n","            csvWriter.writerow(['{}_{}'.format(year, i), df.shape[0],per_ptweets,per_ntweets])\n","\n","csvFile.close() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qpt5wQ1FcvAU","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}